```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gemini AI Music Producer's Studio</title>
    <link rel="stylesheet" href="https://unpkg.com/picnic">
    <script src="https://cdn.jsdelivr.net/npm/@ffmpeg/ffmpeg@0.10.1/dist/ffmpeg.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/universal-sentence-encoder"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/knn-classifier"></script>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
        }
        .header h1 {
            color: #333;
        }
        .controls {
            display: flex;
            justify-content: space-between;
            margin-bottom: 20px;
        }
        .control-group {
            flex: 1;
            margin: 0 10px;
        }
        .control-group label {
            display: block;
            margin-bottom: 5px;
            font-weight: bold;
        }
        .control-group input, .control-group select, .control-group button {
            width: 100%;
            padding: 8px;
            box-sizing: border-box;
        }
        .visualization {
            border: 1px solid #ddd;
            padding: 20px;
            background-color: #fff;
            border-radius: 5px;
            margin-bottom: 20px;
        }
        .visualization canvas {
            width: 100%;
            height: 300px;
            background-color: #f9f9f9;
        }
        .output {
            border: 1px solid #ddd;
            padding: 20px;
            background-color: #fff;
            border-radius: 5px;
        }
        .output pre {
            white-space: pre-wrap;
            word-wrap: break-word;
        }
        .button-group {
            display: flex;
            justify-content: space-between;
            margin-top: 20px;
        }
        .button-group button {
            flex: 1;
            margin: 0 5px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Gemini AI Music Producer's Studio</h1>
        </div>
        <div class="controls">
            <div class="control-group">
                <label for="compositionInput">Music Composition Prompt</label>
                <input type="text" id="compositionInput" placeholder="Enter a prompt for music composition">
            </div>
            <div class="control-group">
                <label for="effectInput">Sound Effect Prompt</label>
                <input type="text" id="effectInput" placeholder="Enter a prompt for sound effects">
            </div>
            <div class="control-group">
                <label for="genreInput">Genre Classification</label>
                <select id="genreInput">
                    <option value="">Select a genre</option>
                    <option value="rock">Rock</option>
                    <option value="pop">Pop</option>
                    <option value="jazz">Jazz</option>
                    <option value="classical">Classical</option>
                    <option value="electronic">Electronic</option>
                </select>
            </div>
        </div>
        <div class="visualization">
            <canvas id="waveformCanvas"></canvas>
        </div>
        <div class="output">
            <pre id="outputText"></pre>
        </div>
        <div class="button-group">
            <button id="generateCompositionBtn">Generate Composition</button>
            <button id="generateEffectBtn">Generate Sound Effect</button>
            <button id="transcribeBtn">Transcribe Music</button>
            <button id="classifyBtn">Classify Genre</button>
            <button id="recommendBtn">Recommend Music</button>
        </div>
    </div>

    <script>
        const { createFFmpeg, fetchFile } = FFmpeg;
        const ffmpeg = createFFmpeg({ log: true });

        let audioContext;
        let analyser;
        let dataArray;
        let canvasCtx;
        let animationId;

        async function loadFFmpeg() {
            if (!ffmpeg.isLoaded()) {
                await ffmpeg.load();
            }
        }

        function setupAudioVisualization() {
            const canvas = document.getElementById('waveformCanvas');
            canvasCtx = canvas.getContext('2d');

            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 256;
            dataArray = new Uint8Array(analyser.frequencyBinCount);

            const source = audioContext.createMediaElementSource(new Audio());
            source.connect(analyser);
            analyser.connect(audioContext.destination);

            draw();
        }

        function draw() {
            animationId = requestAnimationFrame(draw);

            analyser.getByteFrequencyData(dataArray);

            canvasCtx.fillStyle = 'rgb(200, 200, 200)';
            canvasCtx.fillRect(0, 0, canvasCtx.canvas.width, canvasCtx.canvas.height);

            const barWidth = (canvasCtx.canvas.width / analyser.frequencyBinCount) * 2.5;
            let x = 0;

            for (let i = 0; i < analyser.frequencyBinCount; i++) {
                const barHeight = dataArray[i] / 2;

                canvasCtx.fillStyle = `rgb(${barHeight + 100}, 50, 50)`;
                canvasCtx.fillRect(x, canvasCtx.canvas.height - barHeight, barWidth, barHeight);

                x += barWidth + 1;
            }
        }

        async function generateComposition() {
            const prompt = document.getElementById('compositionInput').value;
            if (!prompt) return;

            // Simulate Gemini API call for music composition
            const response = await fetch('https://api.gemini.com/generate', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ prompt, type: 'composition' }),
            });

            const data = await response.json();
            document.getElementById('outputText').textContent = data.composition;

            // Generate audio file from composition
            await generateAudioFile(data.composition, 'composition');
        }

        async function generateEffect() {
            const prompt = document.getElementById('effectInput').value;
            if (!prompt) return;

            // Simulate Gemini API call for sound effect
            const response = await fetch('https://api.gemini.com/generate', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ prompt, type: 'effect' }),
            });

            const data = await response.json();
            document.getElementById('outputText').textContent = data.effect;

            // Generate audio file from sound effect
            await generateAudioFile(data.effect, 'effect');
        }

        async function generateAudioFile(text, type) {
            await loadFFmpeg();

            // Simulate audio generation from text
            const audioData = new Uint8Array([...text].map(c => c.charCodeAt(0)));

            ffmpeg.FS('writeFile', `${type}.wav`, audioData);

            await ffmpeg.run('-i', `${type}.wav`, '-acodec', 'libmp3lame', `${type}.mp3`);

            const data = ffmpeg.FS('readFile', `${type}.mp3');

            const audio = new Audio(URL.createObjectURL(new Blob([data.buffer], { type: 'audio/mp3' })));
            audio.play();

            // Update visualization
            if (animationId) {
                cancelAnimationFrame(animationId);
            }
            setupAudioVisualization();
        }

        async function transcribeMusic() {
            // Simulate music transcription with deep learning
            const response = await fetch('https://api.gemini.com/transcribe', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ audio: 'current_audio' }),
            });

            const data = await response.json();
            document.getElementById('outputText').textContent = data.transcription;
        }

        async function classifyGenre() {
            const genre = document.getElementById('genreInput').value;
            if (!genre) return;

            // Simulate genre classification with machine learning
            const response = await fetch('https://api.gemini.com/classify', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ genre }),
            });

            const data = await response.json();
            document.getElementById('outputText').textContent = data.classification;
        }

        async function recommendMusic() {
            // Simulate music recommendation with collaborative filtering
            const response = await fetch('https://api.gemini.com/recommend', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ user: 'current_user' }),
            });

            const data = await response.json();
            document.getElementById('outputText').textContent = data.recommendations;
        }

        document.getElementById('generateCompositionBtn').addEventListener('click', generateComposition);
        document.getElementById('generateEffectBtn').addEventListener('click', generateEffect);
        document.getElementById('transcribeBtn').addEventListener('click', transcribeMusic);
        document.getElementById('classifyBtn').addEventListener('click', classifyGenre);
        document.getElementById('recommendBtn').addEventListener('click', recommendMusic);

        // Initialize
        setupAudioVisualization();
    </script>
</body>
</html>
```